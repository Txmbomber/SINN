# SINN
Self modifying neural network (SINN)

This code was developed by Chat GPT after going back and forth for about 8hrs modifying and improving it. This code has visualisation to monitor the model (don't know how it looks), I'll upload another version without visualisation (SINN no visuals) to cut down on the code.

Chat GPT thoughts on what it can be used for.

This is a great piece of code for hyperparameter tuning using Keras Tuner! It can be used for a variety of tasks such as image classification, natural language processing, and even audio processing. Here are a few ideas on how you could use this self-improving neural network:
1. Image classification: This code could be used to improve the accuracy of image classification models. You could use this to tune hyperparameters for image classification tasks such as identifying objects in images or recognizing faces.
2. Natural language processing: This code could be used to improve the accuracy of natural language processing models. You could use this to tune hyperparameters for tasks such as sentiment analysis or text classification.
3. Audio processing: This code could be used to improve the accuracy of audio processing models. You could use this to tune hyperparameters for tasks such as speech recognition or speaker identification.
Overall, this code is very versatile and can be used for a variety of tasks. It can be particularly useful for improving the accuracy of machine learning models, which can be challenging to do manually.

Chat GPT's explanation (because I'm to lazy to write it).

The code provided is written in Python and uses TensorFlow and Keras libraries to build and train a neural network. It also uses the Kerastuner library to perform hyperparameter tuning for the model.
Overall, the code seems well-written, with clear variable names and comments that explain the purpose of each section. The code is organized into functions and classes, making it easy to read and understand. The use of callbacks for early stopping and model checkpointing is also a good practice to avoid overfitting and to save the best model weights.
Regarding the model itself, the code builds a sequential neural network with dense layers, batch normalization layers, dropout layers, and activity regularization. The number of layers and their hyperparameters are optimized using the RandomSearch method provided by Kerastuner.
In summary, this code appears to be of high quality and follows best practices for building and training neural networks. It also uses hyperparameter tuning to optimize the model's performance.

--------

Chat GPT rates it out of 10

Code organization: 9/10

Readability: 9/10

Modularity: 8/10

Performance: 8/10

Best practices: 9/10

Overall: 8.5/10 - The code is well-written and follows best practices for deep learning and hyperparameter tuning. However, there is room for improvement in terms of modularity and hyperparameter search space.

--------

Have fun with it, don't get a headache, if you start an AI uprising don't point fingers at me and if you get something good throw my name in I guess.

If you want to report anything like how things went, code not working, improving the code or how much of a dumpster fire it turned out, I have made an Gmail for it (SINN.Replies@gmail.com).
